diff --git a/A3D_MIL_dataset.py b/A3D_MIL_dataset.py
index 48beaf5..1938814 100644
--- a/A3D_MIL_dataset.py
+++ b/A3D_MIL_dataset.py
@@ -1,11 +1,11 @@
 # -*- coding: utf-8 -*-
 #================================================================
-#   God Bless You. 
-#   
+#   God Bless You.
+#
 #   author: klaus
 #   email: klaus.cheng@qq.com
 #   created date: 2019/11/22
-#   description: 
+#   description:
 #
 #================================================================
 import os
@@ -14,55 +14,79 @@ from torchvision import transforms
 import numpy as np
 import torch
 import random
+import json
+
 
 class A3DMILDataset(Dataset):
-    def __init__(self, root_dir, batch_size, transforms = None):
+
+    def __init__(self, root_dir, batch_size, phase='train', transforms=None):
 
         self.normal_vids_dir = os.path.join(root_dir, 'normal')
-        self.anomaly_vids_dir = os.path.join(root_dir, 'anomaly')
+        self.anomaly_vids_dir = os.path.join(root_dir, 'abnormal')
 
-        self.normal_vids = os.listdir(self.normal_vids_dir)  
-        self.anomaly_vids = os.listdir(self.anomaly_vids_dir)  
-        self.all_vids = {'normal': self.normal_vids, 'anomaly':self.anomaly_vids}
+        self.normal_vids = os.listdir(self.normal_vids_dir)[:-1]
+        self.anomaly_vids = os.listdir(self.anomaly_vids_dir)
+        self.all_vids = {'normal': self.normal_vids, 'abnormal': self.anomaly_vids}
 
         self.num_anomaly = len(self.anomaly_vids)
-        self.num_normal = len(self.normal_vids) 
+        self.num_normal = len(self.normal_vids)
 
-        self.batch_size = batch_size # 1 anomaly and 1 normal
-        self.n_exp = self.batch_size/2
+        self.batch_size = batch_size    # 1 abnormal and 1 normal
+        self.n_exp = self.batch_size / 2
 
         self.root_dir = root_dir
 
+        self.phase = phase
+
+        self.abnormal_dict = json.load(
+            open(
+                '/u/xiziwang/projects/stad-cvpr2020/baselines/VideoActionRecognition/pytorch-i3d/A3D_2.0.json'
+            ))
+
     def __getitem__(self, index):
 
-        label = 'normal' 
-        # Normal_features = []
-        # Anomaly_features = []
-        dire = os.path.join(os.path.join(self.root_dir, label), self.all_vids[label][index]  ) 
-        normal_clip_num = len(os.listdir(dire) )
-        # Normal_features = np.zeros(shape=(normal_clip_num, 1024) ) 
         All_features = []
-        for i,iv in enumerate(os.listdir(dire)):
-            feature = np.load(os.path.join(dire, iv) ) 
-            All_features.append(torch.from_numpy(feature) ) 
-        label = 'anomaly'
+        if self.phase == 'train':
+            label = 'normal'
+            # Normal_features = []
+            # Anomaly_features = []
+            dire = os.path.join(os.path.join(self.root_dir, label), self.all_vids[label][index])
+            normal_clip_num = len(os.listdir(dire))
+            # Normal_features = np.zeros(shape=(normal_clip_num, 1024) )
+            for i, iv in enumerate(os.listdir(dire)):
+                feature = np.load(os.path.join(dire, iv))
+                All_features.append(torch.from_numpy(feature))
+        label = 'abnormal'
         # abnormal_clip_num = 0
-        dire = os.path.join(os.path.join(self.root_dir, label), self.all_vids[label][index]  ) 
-        abnormal_clip_num = len(os.listdir(dire) )
-        # Anomaly_features = np.zeros(shape = ( abnormal_clip_num, 1024) ) 
+        dire = os.path.join(os.path.join(self.root_dir, label), self.all_vids[label][index])
+        abnormal_clip_num = len(os.listdir(dire))
+        # Anomaly_features = np.zeros(shape = ( abnormal_clip_num, 1024) )
         for iv in os.listdir(dire):
-            feature = np.load(os.path.join(dire, iv) ) 
-            All_features.append(torch.from_numpy(feature) )  
+            feature = np.load(os.path.join(dire, iv))
+            All_features.append(torch.from_numpy(feature))
 
-        Normal_labels = np.zeros(normal_clip_num, dtype = 'uint8') 
+        if self.phase == 'train':
+            Normal_labels = np.zeros(normal_clip_num, dtype='uint8')
+            Anomaly_labels = np.ones(abnormal_clip_num, dtype='uint8')
+            All_labels = np.concatenate((Normal_labels, Anomaly_labels))
 
-        Anomaly_labels = np.ones(abnormal_clip_num, dtype = 'uint8') 
-        
-        All_features = torch.stack(All_features, dim=0) 
-        All_labels = np.concatenate((Normal_labels, Anomaly_labels)) 
-        # print(All_labels.shape) 
-        All_labels = torch.from_numpy(All_labels) 
+        else:
+            print(self.abnormal_dict[self.all_vids[label][index]])
+            print(self.abnormal_dict[self.all_vids[label][index]]['anomaly_start'])
+            print(self.abnormal_dict[self.all_vids[label][index]]['anomaly_end'])
+            Anomaly_labels = np.zeros(self.abnormal_dict[self.all_vids[label][index]]['num_frames'],
+                                      dtype='uint8')
+            for i in range(self.abnormal_dict[self.all_vids[label][index]]['anomaly_start'] - 1,
+                           self.abnormal_dict[self.all_vids[label][index]]['anomaly_end'] - 1):
+                Anomaly_labels[i] = 1
+            All_labels = Anomaly_labels
+        All_features = torch.stack(All_features, dim=0)
+        # print(All_labels.shape)
+        All_labels = torch.from_numpy(All_labels)
         return All_features, All_labels
-         
+
     def __len__(self):
-        return self.num_anomaly
+        if self.phase == 'train':
+            return self.num_normal
+        else:
+            return self.num_anomaly
diff --git a/__pycache__/A3D_MIL_dataset.cpython-36.pyc b/__pycache__/A3D_MIL_dataset.cpython-36.pyc
index 6cbd649..e91a0dc 100644
Binary files a/__pycache__/A3D_MIL_dataset.cpython-36.pyc and b/__pycache__/A3D_MIL_dataset.cpython-36.pyc differ
diff --git a/__pycache__/pred_head.cpython-36.pyc b/__pycache__/pred_head.cpython-36.pyc
index 8e146dc..df571d0 100644
Binary files a/__pycache__/pred_head.cpython-36.pyc and b/__pycache__/pred_head.cpython-36.pyc differ
diff --git a/__pycache__/trainer.cpython-36.pyc b/__pycache__/trainer.cpython-36.pyc
index 3c68be8..7581e43 100644
Binary files a/__pycache__/trainer.cpython-36.pyc and b/__pycache__/trainer.cpython-36.pyc differ
diff --git a/pred_head.py b/pred_head.py
index 34df10c..5b287ff 100644
--- a/pred_head.py
+++ b/pred_head.py
@@ -1,23 +1,27 @@
 import torch
 import torch.nn as nn
 
+
 def init_weights(m):
     if type(m) == nn.Linear:
         torch.nn.init.xavier_normal_(m.weight)
-        m.bias.data.fill_(0.01)  
+        m.bias.data.fill_(0.01)
+
 
 class PredHead(nn.Module):
+
     def __init__(self):
         super(PredHead, self).__init__()
-        self.model = nn.Sequential(nn.Linear(1024, 512),
-                                nn.ReLU(),
-                                # nn.Dropout(0.9),
-                                nn.Linear(512, 32),
-                                nn.ReLU(),
-                                # nn.Dropout(0.9),
-                                nn.Linear(32, 1),
-                                nn.Sigmoid(),
-                                )
+        self.model = nn.Sequential(
+            nn.Linear(1024, 512),
+            nn.ReLU(),
+        # nn.Dropout(0.9),
+            nn.Linear(512, 32),
+            nn.ReLU(),
+        # nn.Dropout(0.9),
+            nn.Linear(32, 1),
+            nn.Sigmoid(),
+        )
 
         self.model.apply(init_weights)
 
diff --git a/train_MIL.py b/train_MIL.py
index 40ae250..bce152e 100644
--- a/train_MIL.py
+++ b/train_MIL.py
@@ -5,6 +5,11 @@ from pred_head import PredHead
 from A3D_MIL_dataset import A3DMILDataset
 from tqdm import tqdm
 import torch.nn.functional as F
+import wandb
+from sklearn import metrics
+import numpy as np
+
+wandb.init()
 
 use_cuda = torch.cuda.is_available()
 
@@ -12,34 +17,39 @@ device = torch.device("cuda:0" if use_cuda else "cpu")
 # cudnn.benchmark = True
 
 # Parameters
-params = {'batch_size': 1,
-          'shuffle': True,
-          'num_workers': 1}
+params = {'batch_size': 1, 'shuffle': True, 'num_workers': 1}
 
 max_epochs = 10000
 
-training_set = A3DMILDataset('/home/data/vision7/A3D_frame_feat/', batch_size=2)
+training_set = A3DMILDataset('/home/data/vision7/A3D_feat/train', batch_size=2)
 data_loader = data.DataLoader(training_set, **params)
-test_loader = data.DataLoader(training_set, **params) 
+# test_loader = data.DataLoader(training_set, **params)
+
+val_set = A3DMILDataset('/home/data/vision7/A3D_feat/val', batch_size=1, phase='val')
+val_dataloader = data.DataLoader(val_set, **params)
+
+net = PredHead()
+net.cuda()
+wandb.watch(net)
 
-net = PredHead() 
-net.cuda() 
 for params in net.parameters():
     params.requires_grad = True
 
+
 def loss_fn(outputs, labels):
     batch_size = outputs.size()[0]
-    normal_max = torch.max(outputs.view(1, 1, -1) *(1.0-labels))
-    abnormal_max = torch.max(outputs.view(1,1,-1) *labels)
-    return torch.max(torch.tensor(0.0).cuda(), 1.0-abnormal_max+normal_max)
+    normal_max = torch.max(outputs.view(1, 1, -1) * (1.0 - labels))
+    abnormal_max = torch.max(outputs.view(1, 1, -1) * labels)
+    return torch.max(torch.tensor(0.0).cuda(), 1.0 - abnormal_max + normal_max)
 
-optimizer = torch.optim.SGD(net.parameters(), lr = 0.001)
-# optimizer = torch.optim.Adam(net.parameters(), lr = 0.0001 )
 
+optimizer = torch.optim.SGD(net.parameters(), lr=0.001)
+# optimizer = torch.optim.Adam(net.parameters(), lr = 0.0001 )
 for epoch in range(max_epochs):
     # Training
+    net.train()
     running_loss = 0.0
-    net.train() 
+    # net.train()
     for idx, (local_batch, local_labels) in enumerate(tqdm(data_loader)):
         # Transfer to GPU
         local_batch, local_labels = local_batch.to(device), local_labels.to(device)
@@ -47,30 +57,45 @@ for epoch in range(max_epochs):
         outputs = net(local_batch)
         loss = loss_fn(outputs, local_labels)
         # if idx % 10 == 0:
-            # print(outputs, local_labels, loss) 
-        running_loss += (loss.item() - running_loss) / (idx+1)
+        # print(outputs, local_labels, loss)
+        running_loss += (loss.item() - running_loss) / (idx + 1)
         loss.backward()
         optimizer.step()
-    print(running_loss) 
+        # if idx % 10 == 0:
+        # wandb.log({"loss": running_loss})
+
+    net.eval()
+    # print(running_loss)
     correct = 0
     total = 0
-    print("=========begin to eval==========") 
+    print("=========begin to eval==========")
     test_running_loss = 0
     with torch.no_grad():
-        net.eval() 
-        for idx,(batch,label) in enumerate(data_loader):
+        net.eval()
+        for idx, (batch, label) in enumerate(val_dataloader):
             batch = batch.to(device)
-            label = label.to(device)  
+            label = label.to(device)
             outputs = net(batch)
-            loss = loss_fn(outputs, label)
-            if idx % 10 == 0:
-                print(outputs, label,loss) 
-            outputs = outputs.view(1,1,-1) 
-            ones = torch.ones(outputs.shape).cuda() 
-            zeros = torch.zeros(outputs.shape).cuda() 
-            predicted = torch.where(outputs>0.5, ones, zeros) 
-            total += label.size(1)
-            correct += (predicted == label).sum().item()
-            test_running_loss += (loss.item() - test_running_loss) / (idx+1)
-    print(test_running_loss) 
-    print('Accuracy of the network on the epoch : %d %%' % (100* correct / total) ) 
+            # loss = loss_fn(outputs, label)
+            # if idx % 10 == 0:
+            # print(outputs, label, loss)
+            outputs = outputs.view(1, 1, -1)
+            ones = torch.ones(outputs.shape).cuda()
+            zeros = torch.zeros(outputs.shape).cuda()
+            predicted = torch.where(outputs > 0.5, ones, zeros)
+            # total += label.size(1)
+            # correct += (predicted == label).sum().item()
+            # test_running_loss += (loss.item() - test_running_loss) / (idx + 1)
+            pred = predicted.cpu().numpy()
+            pred = pred[0][0][:-1]
+            pred_labels_pop = np.zeros(len(pred) * 16, dtype='uint8')
+            for i in range(len(pred)):
+                if pred[i] == 1:
+                    for j in range(16):
+                        pred_labels_pop[16 * i + j] = 1
+            y = label.cpu().numpy()[0][:len(pred_labels_pop)]
+            print(y, pred_labels_pop)
+        fpr, tpr, thresholds = metrics.roc_curve(y, pred_labels_pop, pos_label=1)
+        # wandb.log({"auc": metrics.auc(fpr, tpr)})
+    # print(test_running_loss)
+    print('Accuracy of the network on the epoch : %d %%' % (100 * correct / total))
